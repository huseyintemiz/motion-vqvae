{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install scipy==1.10.1 numpy==1.21.5\n",
    "#restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/huseyintemiz/motion-vqvae.git\n",
    "cd motion-vqvae\n",
    "\n",
    "# mkdir dataset\n",
    "cd dataset\n",
    "!gdown \"https://drive.google.com/uc?id=18UNPgcNOYpKh6ZyS1bH-gl4uq9zP-_ZL\"\n",
    "echo -e \"Downloading done!\"\n",
    "\n",
    "unzip HumanML3D.zip\n",
    "echo -e \"Unzip done!\"\n",
    "\n",
    "cd ..\n",
    "\n",
    "pip install -r req2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting ipykernel\n",
      "  Downloading ipykernel-6.29.4-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nest-asyncio\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting debugpy>=1.6.5\n",
      "  Downloading debugpy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tornado>=6.1\n",
      "  Downloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.4/435.4 kB\u001b[0m \u001b[31m380.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting traitlets>=5.4.0\n",
      "  Downloading traitlets-5.14.2-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m349.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyter-client>=6.1.12\n",
      "  Downloading jupyter_client-8.6.1-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m362.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging\n",
      "  Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m233.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyter-core!=5.0.*,>=4.12\n",
      "  Downloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "Collecting comm>=0.1.1\n",
      "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting matplotlib-inline>=0.1\n",
      "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Collecting pyzmq>=24\n",
      "  Downloading pyzmq-25.1.2-cp310-cp310-manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m178.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipython>=7.23.1\n",
      "  Downloading ipython-8.22.2-py3-none-any.whl (811 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m168.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pexpect>4.3\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m305.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pygments>=2.4.0\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m183.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting decorator\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting jedi>=0.16\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m139.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting stack-data\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting prompt-toolkit<3.1.0,>=3.0.41\n",
      "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.1/386.1 kB\u001b[0m \u001b[31m290.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m358.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting platformdirs>=2.5\n",
      "  Downloading platformdirs-4.2.0-py3-none-any.whl (17 kB)\n",
      "Collecting parso<0.9.0,>=0.8.3\n",
      "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m341.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pure-eval\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting asttokens>=2.1.0\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting executing>=1.2.0\n",
      "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wcwidth, pure-eval, ptyprocess, traitlets, tornado, six, pyzmq, pygments, psutil, prompt-toolkit, platformdirs, pexpect, parso, packaging, nest-asyncio, executing, exceptiongroup, decorator, debugpy, python-dateutil, matplotlib-inline, jupyter-core, jedi, comm, asttokens, stack-data, jupyter-client, ipython, ipykernel\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.13\n",
      "    Uninstalling wcwidth-0.2.13:\n",
      "      Successfully uninstalled wcwidth-0.2.13\n",
      "  Attempting uninstall: pure-eval\n",
      "    Found existing installation: pure-eval 0.2.2\n",
      "    Uninstalling pure-eval-0.2.2:\n",
      "      Successfully uninstalled pure-eval-0.2.2\n",
      "  Attempting uninstall: ptyprocess\n",
      "    Found existing installation: ptyprocess 0.7.0\n",
      "    Uninstalling ptyprocess-0.7.0:\n",
      "      Successfully uninstalled ptyprocess-0.7.0\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.14.2\n",
      "    Uninstalling traitlets-5.14.2:\n",
      "      Successfully uninstalled traitlets-5.14.2\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.4\n",
      "    Uninstalling tornado-6.4:\n",
      "      Successfully uninstalled tornado-6.4\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 25.1.2\n",
      "    Uninstalling pyzmq-25.1.2:\n",
      "      Successfully uninstalled pyzmq-25.1.2\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.17.2\n",
      "    Uninstalling Pygments-2.17.2:\n",
      "      Successfully uninstalled Pygments-2.17.2\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.8\n",
      "    Uninstalling psutil-5.9.8:\n",
      "      Successfully uninstalled psutil-5.9.8\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.43\n",
      "    Uninstalling prompt-toolkit-3.0.43:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.43\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.2.0\n",
      "    Uninstalling platformdirs-4.2.0:\n",
      "      Successfully uninstalled platformdirs-4.2.0\n",
      "  Attempting uninstall: pexpect\n",
      "    Found existing installation: pexpect 4.9.0\n",
      "    Uninstalling pexpect-4.9.0:\n",
      "      Successfully uninstalled pexpect-4.9.0\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.3\n",
      "    Uninstalling parso-0.8.3:\n",
      "      Successfully uninstalled parso-0.8.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.6.0\n",
      "    Uninstalling nest-asyncio-1.6.0:\n",
      "      Successfully uninstalled nest-asyncio-1.6.0\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 2.0.1\n",
      "    Uninstalling executing-2.0.1:\n",
      "      Successfully uninstalled executing-2.0.1\n",
      "  Attempting uninstall: exceptiongroup\n",
      "    Found existing installation: exceptiongroup 1.2.0\n",
      "    Uninstalling exceptiongroup-1.2.0:\n",
      "      Successfully uninstalled exceptiongroup-1.2.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "  Attempting uninstall: debugpy\n",
      "    Found existing installation: debugpy 1.8.1\n",
      "    Uninstalling debugpy-1.8.1:\n",
      "      Successfully uninstalled debugpy-1.8.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: matplotlib-inline\n",
      "    Found existing installation: matplotlib-inline 0.1.6\n",
      "    Uninstalling matplotlib-inline-0.1.6:\n",
      "      Successfully uninstalled matplotlib-inline-0.1.6\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter_core 5.7.2\n",
      "    Uninstalling jupyter_core-5.7.2:\n",
      "      Successfully uninstalled jupyter_core-5.7.2\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.19.1\n",
      "    Uninstalling jedi-0.19.1:\n",
      "      Successfully uninstalled jedi-0.19.1\n",
      "  Attempting uninstall: comm\n",
      "    Found existing installation: comm 0.2.2\n",
      "    Uninstalling comm-0.2.2:\n",
      "      Successfully uninstalled comm-0.2.2\n",
      "  Attempting uninstall: asttokens\n",
      "    Found existing installation: asttokens 2.4.1\n",
      "    Uninstalling asttokens-2.4.1:\n",
      "      Successfully uninstalled asttokens-2.4.1\n",
      "  Attempting uninstall: stack-data\n",
      "    Found existing installation: stack-data 0.6.3\n",
      "    Uninstalling stack-data-0.6.3:\n",
      "      Successfully uninstalled stack-data-0.6.3\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter_client 8.6.1\n",
      "    Uninstalling jupyter_client-8.6.1:\n",
      "      Successfully uninstalled jupyter_client-8.6.1\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.22.2\n",
      "    Uninstalling ipython-8.22.2:\n",
      "      Successfully uninstalled ipython-8.22.2\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 6.29.4\n",
      "    Uninstalling ipykernel-6.29.4:\n",
      "      Successfully uninstalled ipykernel-6.29.4\n",
      "Successfully installed asttokens-2.4.1 comm-0.2.2 debugpy-1.8.1 decorator-5.1.1 exceptiongroup-1.2.0 executing-2.0.1 ipykernel-6.29.4 ipython-8.22.2 jedi-0.19.1 jupyter-client-8.6.1 jupyter-core-5.7.2 matplotlib-inline-0.1.6 nest-asyncio-1.6.0 packaging-24.0 parso-0.8.3 pexpect-4.9.0 platformdirs-4.2.0 prompt-toolkit-3.0.43 psutil-5.9.8 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.17.2 python-dateutil-2.9.0.post0 pyzmq-25.1.2 six-1.16.0 stack-data-0.6.3 tornado-6.4 traitlets-5.14.2 wcwidth-0.2.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel -U --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "batch_size: 64\n",
      "checkpoints_dir: ./checkpoints\n",
      "code_dim: 512\n",
      "commit: 0.02\n",
      "dataset_name: t2m\n",
      "depth: 3\n",
      "dilation_growth_rate: 3\n",
      "down_t: 2\n",
      "eval_every_e: 1\n",
      "ext: default\n",
      "feat_bias: 5\n",
      "gamma: 0.05\n",
      "gpu_id: 0\n",
      "is_continue: False\n",
      "log_every: 10\n",
      "loss_vel: 0.5\n",
      "lr: 0.0002\n",
      "max_epoch: 50\n",
      "milestones: [150000, 250000]\n",
      "mu: 0.99\n",
      "name: lfq_namexx\n",
      "nb_code: 512\n",
      "num_quantizers: 6\n",
      "output_emb_width: 512\n",
      "quantize_dropout_prob: 0.2\n",
      "recons_loss: l1_smooth\n",
      "save_every_e: 2\n",
      "save_latest: 500\n",
      "seed: 3407\n",
      "shared_codebook: False\n",
      "stride_t: 2\n",
      "vq_act: relu\n",
      "vq_name: rvq_nq6_dc512_nc512_noshare_qdp0.2\n",
      "vq_norm: None\n",
      "warm_up_iter: 2000\n",
      "weight_decay: 0.0\n",
      "which_epoch: all\n",
      "width: 512\n",
      "window_size: 64\n",
      "-------------- End ----------------\n",
      "Using Device: cuda:0\n",
      "Reading ./checkpoints/t2m/Comp_v6_KLD005/opt.txt\n",
      "Loading Evaluation Model Wrapper (Epoch 28) Completed!!\n",
      "RVQVAE(\n",
      "  (encoder): Encoder(\n",
      "    (model): Sequential(\n",
      "      (0): Conv1d(263, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "        (1): Resnet1D(\n",
      "          (model): Sequential(\n",
      "            (0): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "            (1): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "            (2): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "        (1): Resnet1D(\n",
      "          (model): Sequential(\n",
      "            (0): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "            (1): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "            (2): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (model): Sequential(\n",
      "      (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): Sequential(\n",
      "        (0): Resnet1D(\n",
      "          (model): Sequential(\n",
      "            (0): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "            (1): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "            (2): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Resnet1D(\n",
      "          (model): Sequential(\n",
      "            (0): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "            (1): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "            (2): ResConv1DBlock(\n",
      "              (norm1): Identity()\n",
      "              (norm2): Identity()\n",
      "              (activation1): ReLU()\n",
      "              (activation2): ReLU()\n",
      "              (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "              (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      )\n",
      "      (4): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (5): ReLU()\n",
      "      (6): Conv1d(512, 263, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    )\n",
      "  )\n",
      "  (quantizer3): ResidualVQ(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x QuantizeEMAReset()\n",
      "    )\n",
      "  )\n",
      "  (quantizer2): ResidualLFQ(\n",
      "    (project_in): Linear(in_features=512, out_features=12, bias=True)\n",
      "    (project_out): Linear(in_features=12, out_features=512, bias=True)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LFQ(\n",
      "        (project_in): Identity()\n",
      "        (project_out): Identity()\n",
      "        (activation): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (quantizer): LFQ(\n",
      "    (project_in): Linear(in_features=512, out_features=9, bias=True)\n",
      "    (project_out): Linear(in_features=9, out_features=512, bias=True)\n",
      "    (activation): Identity()\n",
      "  )\n",
      ")\n",
      "Total parameters of all models: 19.459356M\n",
      "100%|████████████████████████████████████| 23384/23384 [00:24<00:00, 968.06it/s]\n",
      "Total number of motions 20942, snippets 1847722\n",
      "100%|██████████████████████████████████████| 1460/1460 [00:01<00:00, 989.96it/s]\n",
      "Total number of motions 1300, snippets 116698\n",
      "Reading ./checkpoints/t2m/Comp_v6_KLD005/opt.txt\n",
      "Loading dataset t2m ...\n",
      "100%|██████████████████████████████████████| 4384/4384 [00:05<00:00, 783.94it/s]\n",
      "Pointer Pointing at 0\n",
      "Ground Truth Dataset Loading Completed!!!\n",
      "Total Epochs: 50, Total Iters: 1443500\n",
      "Iters Per Epoch, Training: 28870, Validation: 145\n",
      "--> \t Eva. Ep 0:, FID. 78.5310, Diversity Real. 9.3572, Diversity. 0.4811, R_precision_real. (0.5125, 0.7011, 0.8006), R_precision. (0.0078, 0.0177, 0.0338), matching_score_real. 2.9737, matching_score_pred. 8.8171\n",
      "--> --> \t FID Improved from 1000.00000 to 78.53097 !!!\n",
      "--> --> \t Diversity Improved from 100.00000 to 0.48112 !!!\n",
      "--> --> \t Top1 Improved from 0.00000 to 0.00776 !!!\n",
      "--> --> \t Top2 Improved from 0.00000 to 0.01767!!!\n",
      "--> --> \t Top3 Improved from 0.00000 to 0.03384 !!!\n",
      "--> --> \t matching_score Improved from 100.00000 to 8.81709 !!!\n",
      "ep/it: 0-   9 niter:    10  0m 10s (- 25153m 23s) completed:  0%) loss: 1.0353  loss_rec: 0.8553  loss_vel: 0.3781  loss_commit: -0.4544  perplexity: -1.8176  lr: 0.0000 \n",
      "ep/it: 0-  19 niter:    20  0m 11s (- 13294m 34s) completed:  0%) loss: 1.0356  loss_rec: 0.8400  loss_vel: 0.4107  loss_commit: -0.4895  perplexity: -1.9581  lr: 0.0000 \n",
      "ep/it: 0-  29 niter:    30  0m 11s (- 9334m 17s) completed:  0%) loss: 1.0014  loss_rec: 0.8308  loss_vel: 0.3617  loss_commit: -0.5155  perplexity: -2.0619  lr: 0.0000 \n",
      "ep/it: 0-  39 niter:    40  0m 12s (- 7357m 25s) completed:  0%) loss: 1.0193  loss_rec: 0.8427  loss_vel: 0.3742  loss_commit: -0.5256  perplexity: -2.1024  lr: 0.0000 \n",
      "ep/it: 0-  49 niter:    50  0m 12s (- 6171m 45s) completed:  0%) loss: 0.9659  loss_rec: 0.7930  loss_vel: 0.3666  loss_commit: -0.5210  perplexity: -2.0838  lr: 0.0000 \n",
      "ep/it: 0-  59 niter:    60  0m 13s (- 5377m 51s) completed:  0%) loss: 0.9963  loss_rec: 0.8245  loss_vel: 0.3639  loss_commit: -0.5093  perplexity: -2.0373  lr: 0.0000 \n",
      "ep/it: 0-  69 niter:    70  0m 13s (- 4810m 28s) completed:  0%) loss: 1.0214  loss_rec: 0.8364  loss_vel: 0.3866  loss_commit: -0.4109  perplexity: -1.6434  lr: 0.0000 \n",
      "ep/it: 0-  79 niter:    80  0m 14s (- 4394m 47s) completed:  0%) loss: 1.0022  loss_rec: 0.8250  loss_vel: 0.3639  loss_commit: -0.2391  perplexity: -0.9566  lr: 0.0000 \n",
      "ep/it: 0-  89 niter:    90  0m 15s (- 4065m 6s) completed:  0%) loss: 1.0115  loss_rec: 0.8275  loss_vel: 0.3524  loss_commit: 0.3899  perplexity: 1.5595  lr: 0.0000 \n",
      "ep/it: 0-  99 niter:   100  0m 15s (- 3805m 21s) completed:  0%) loss: 1.0687  loss_rec: 0.8247  loss_vel: 0.3417  loss_commit: 3.6546  perplexity: 14.6185  lr: 0.0000 \n",
      "ep/it: 0- 109 niter:   110  0m 16s (- 3590m 7s) completed:  0%) loss: 1.0728  loss_rec: 0.7975  loss_vel: 0.3031  loss_commit: 6.1858  perplexity: 24.7431  lr: 0.0000 \n",
      "ep/it: 0- 119 niter:   120  0m 17s (- 3409m 35s) completed:  0%) loss: 1.3602  loss_rec: 0.7562  loss_vel: 0.2979  loss_commit: 22.7511  perplexity: 91.0043  lr: 0.0000 \n",
      "ep/it: 0- 129 niter:   130  0m 17s (- 3259m 49s) completed:  0%) loss: 2.2834  loss_rec: 0.7135  loss_vel: 0.3223  loss_commit: 70.4363  perplexity: 281.7454  lr: 0.0000 \n",
      "ep/it: 0- 139 niter:   140  0m 18s (- 3129m 49s) completed:  0%) loss: 1.6494  loss_rec: 0.7151  loss_vel: 0.3065  loss_commit: 39.0497  perplexity: 156.1988  lr: 0.0000 \n",
      "ep/it: 0- 149 niter:   150  0m 18s (- 3016m 38s) completed:  0%) loss: 1.4832  loss_rec: 0.6720  loss_vel: 0.2990  loss_commit: 33.0838  perplexity: 132.3354  lr: 0.0000 \n",
      "ep/it: 0- 159 niter:   160  0m 19s (- 2915m 45s) completed:  0%) loss: 1.4107  loss_rec: 0.7278  loss_vel: 0.2939  loss_commit: 26.7967  perplexity: 107.1868  lr: 0.0000 \n",
      "ep/it: 0- 169 niter:   170  0m 19s (- 2828m 49s) completed:  0%) loss: 1.6490  loss_rec: 0.7143  loss_vel: 0.3115  loss_commit: 38.9515  perplexity: 155.8058  lr: 0.0000 \n",
      "ep/it: 0- 179 niter:   180  0m 20s (- 2754m 28s) completed:  0%) loss: 1.4694  loss_rec: 0.6628  loss_vel: 0.2816  loss_commit: 33.2910  perplexity: 133.1640  lr: 0.0000 \n",
      "ep/it: 0- 189 niter:   190  0m 21s (- 2683m 22s) completed:  0%) loss: 2.0544  loss_rec: 0.6954  loss_vel: 0.2916  loss_commit: 60.6580  perplexity: 242.6320  lr: 0.0000 \n",
      "ep/it: 0- 199 niter:   200  0m 21s (- 2620m 23s) completed:  0%) loss: 1.7886  loss_rec: 0.6763  loss_vel: 0.2848  loss_commit: 48.4967  perplexity: 193.9866  lr: 0.0000 \n",
      "ep/it: 0- 209 niter:   210  0m 22s (- 2566m 5s) completed:  0%) loss: 2.0825  loss_rec: 0.6589  loss_vel: 0.2793  loss_commit: 64.1941  perplexity: 256.7764  lr: 0.0000 \n",
      "ep/it: 0- 219 niter:   220  0m 22s (- 2513m 41s) completed:  0%) loss: 1.2196  loss_rec: 0.6545  loss_vel: 0.2796  loss_commit: 21.2639  perplexity: 85.0557  lr: 0.0000 \n",
      "ep/it: 0- 229 niter:   230  0m 23s (- 2466m 2s) completed:  0%) loss: 1.3807  loss_rec: 0.6864  loss_vel: 0.3003  loss_commit: 27.2055  perplexity: 108.8220  lr: 0.0000 \n",
      "ep/it: 0- 239 niter:   240  0m 24s (- 2422m 1s) completed:  0%) loss: 2.5468  loss_rec: 0.6536  loss_vel: 0.2900  loss_commit: 87.4085  perplexity: 349.6341  lr: 0.0000 \n",
      "ep/it: 0- 249 niter:   250  0m 24s (- 2381m 46s) completed:  0%) loss: 1.9976  loss_rec: 0.6652  loss_vel: 0.2853  loss_commit: 59.4879  perplexity: 237.9516  lr: 0.0000 \n",
      "ep/it: 0- 259 niter:   260  0m 25s (- 2344m 55s) completed:  0%) loss: 1.0906  loss_rec: 0.6689  loss_vel: 0.2719  loss_commit: 14.2857  perplexity: 57.1427  lr: 0.0000 \n",
      "ep/it: 0- 269 niter:   270  0m 25s (- 2311m 54s) completed:  0%) loss: 0.8696  loss_rec: 0.6302  loss_vel: 0.2681  loss_commit: 5.2683  perplexity: 21.0734  lr: 0.0000 \n",
      "ep/it: 0- 279 niter:   280  0m 26s (- 2280m 8s) completed:  0%) loss: 0.9310  loss_rec: 0.6690  loss_vel: 0.2847  loss_commit: 5.9811  perplexity: 23.9245  lr: 0.0000 \n",
      "ep/it: 0- 289 niter:   290  0m 27s (- 2250m 56s) completed:  0%) loss: 0.9094  loss_rec: 0.6667  loss_vel: 0.2676  loss_commit: 5.4443  perplexity: 21.7771  lr: 0.0000 \n",
      "ep/it: 0- 299 niter:   300  0m 27s (- 2223m 36s) completed:  0%) loss: 0.9947  loss_rec: 0.6516  loss_vel: 0.2770  loss_commit: 10.2284  perplexity: 40.9136  lr: 0.0000 \n",
      "ep/it: 0- 309 niter:   310  0m 28s (- 2197m 43s) completed:  0%) loss: 1.2769  loss_rec: 0.6709  loss_vel: 0.2961  loss_commit: 22.8983  perplexity: 91.5932  lr: 0.0000 \n",
      "ep/it: 0- 319 niter:   320  0m 28s (- 2173m 25s) completed:  0%) loss: 3.4609  loss_rec: 0.6337  loss_vel: 0.2932  loss_commit: 134.0298  perplexity: 536.1192  lr: 0.0000 \n",
      "ep/it: 0- 329 niter:   330  0m 29s (- 2150m 55s) completed:  0%) loss: 4.2253  loss_rec: 0.6415  loss_vel: 0.2918  loss_commit: 171.8969  perplexity: 687.5874  lr: 0.0000 \n",
      "ep/it: 0- 339 niter:   340  0m 30s (- 2129m 47s) completed:  0%) loss: 2.3927  loss_rec: 0.6413  loss_vel: 0.2544  loss_commit: 81.2060  perplexity: 324.8241  lr: 0.0000 \n",
      "ep/it: 0- 349 niter:   350  0m 30s (- 2110m 0s) completed:  0%) loss: 1.5061  loss_rec: 0.6260  loss_vel: 0.2864  loss_commit: 36.8441  perplexity: 147.3762  lr: 0.0000 \n",
      "ep/it: 0- 359 niter:   360  0m 31s (- 2091m 16s) completed:  0%) loss: 1.0566  loss_rec: 0.6141  loss_vel: 0.2812  loss_commit: 15.0930  perplexity: 60.3720  lr: 0.0000 \n",
      "ep/it: 0- 369 niter:   370  0m 31s (- 2073m 31s) completed:  0%) loss: 0.9713  loss_rec: 0.6339  loss_vel: 0.2641  loss_commit: 10.2646  perplexity: 41.0585  lr: 0.0000 \n",
      "ep/it: 0- 379 niter:   380  0m 32s (- 2056m 37s) completed:  0%) loss: 0.9463  loss_rec: 0.5985  loss_vel: 0.2504  loss_commit: 11.1266  perplexity: 44.5062  lr: 0.0000 \n",
      "ep/it: 0- 389 niter:   390  0m 33s (- 2040m 46s) completed:  0%) loss: 1.0526  loss_rec: 0.6097  loss_vel: 0.2418  loss_commit: 16.1008  perplexity: 64.4031  lr: 0.0000 \n",
      "ep/it: 0- 399 niter:   400  0m 33s (- 2025m 5s) completed:  0%) loss: 1.0539  loss_rec: 0.6061  loss_vel: 0.2519  loss_commit: 16.0917  perplexity: 64.3667  lr: 0.0000 \n",
      "ep/it: 0- 409 niter:   410  0m 34s (- 2010m 9s) completed:  0%) loss: 1.4297  loss_rec: 0.6031  loss_vel: 0.2527  loss_commit: 35.0084  perplexity: 140.0335  lr: 0.0000 \n",
      "ep/it: 0- 419 niter:   420  0m 34s (- 1996m 9s) completed:  0%) loss: 2.0108  loss_rec: 0.6334  loss_vel: 0.2730  loss_commit: 62.0437  perplexity: 248.1749  lr: 0.0000 \n",
      "ep/it: 0- 429 niter:   430  0m 35s (- 1982m 58s) completed:  0%) loss: 1.2817  loss_rec: 0.6021  loss_vel: 0.2552  loss_commit: 27.6006  perplexity: 110.4024  lr: 0.0000 \n",
      "ep/it: 0- 439 niter:   440  0m 36s (- 1970m 20s) completed:  0%) loss: 2.3561  loss_rec: 0.6160  loss_vel: 0.2717  loss_commit: 80.2095  perplexity: 320.8378  lr: 0.0000 \n",
      "ep/it: 0- 449 niter:   450  0m 36s (- 1958m 5s) completed:  0%) loss: 3.2601  loss_rec: 0.6057  loss_vel: 0.2602  loss_commit: 126.2172  perplexity: 504.8686  lr: 0.0000 \n",
      "ep/it: 0- 459 niter:   460  0m 37s (- 1947m 17s) completed:  0%) loss: 2.1290  loss_rec: 0.5991  loss_vel: 0.2457  loss_commit: 70.3511  perplexity: 281.4044  lr: 0.0000 \n",
      "ep/it: 0- 469 niter:   470  0m 37s (- 1936m 18s) completed:  0%) loss: 1.8066  loss_rec: 0.6115  loss_vel: 0.2625  loss_commit: 53.1902  perplexity: 212.7608  lr: 0.0000 \n",
      "ep/it: 0- 479 niter:   480  0m 38s (- 1925m 22s) completed:  0%) loss: 2.7216  loss_rec: 0.6422  loss_vel: 0.2593  loss_commit: 97.4874  perplexity: 389.9496  lr: 0.0000 \n",
      "ep/it: 0- 489 niter:   490  0m 39s (- 1914m 52s) completed:  0%) loss: 2.4738  loss_rec: 0.5803  loss_vel: 0.2363  loss_commit: 88.7629  perplexity: 355.0514  lr: 0.0000 \n",
      "ep/it: 0- 499 niter:   500  0m 39s (- 1905m 0s) completed:  0%) loss: 2.0411  loss_rec: 0.5958  loss_vel: 0.2446  loss_commit: 66.1539  perplexity: 264.6155  lr: 0.0000 \n",
      "ep/it: 0- 509 niter:   510  0m 40s (- 1904m 45s) completed:  0%) loss: 2.4667  loss_rec: 0.5777  loss_vel: 0.2334  loss_commit: 88.6173  perplexity: 354.4693  lr: 0.0001 \n",
      "ep/it: 0- 519 niter:   520  0m 40s (- 1895m 36s) completed:  0%) loss: 2.4863  loss_rec: 0.5854  loss_vel: 0.2274  loss_commit: 89.3607  perplexity: 357.4427  lr: 0.0001 \n",
      "ep/it: 0- 529 niter:   530  0m 41s (- 1886m 50s) completed:  0%) loss: 3.3791  loss_rec: 0.5882  loss_vel: 0.2641  loss_commit: 132.9450  perplexity: 531.7798  lr: 0.0001 \n",
      "ep/it: 0- 539 niter:   540  0m 42s (- 1878m 27s) completed:  0%) loss: 2.6550  loss_rec: 0.6228  loss_vel: 0.2577  loss_commit: 95.1659  perplexity: 380.6635  lr: 0.0001 \n",
      "ep/it: 0- 549 niter:   550  0m 42s (- 1870m 9s) completed:  0%) loss: 2.4636  loss_rec: 0.5985  loss_vel: 0.2369  loss_commit: 87.3336  perplexity: 349.3343  lr: 0.0001 \n",
      "ep/it: 0- 559 niter:   560  0m 43s (- 1862m 52s) completed:  0%) loss: 2.9157  loss_rec: 0.5940  loss_vel: 0.2345  loss_commit: 110.2225  perplexity: 440.8899  lr: 0.0001 \n",
      "ep/it: 0- 569 niter:   570  0m 43s (- 1856m 9s) completed:  0%) loss: 2.1318  loss_rec: 0.5761  loss_vel: 0.2249  loss_commit: 72.1623  perplexity: 288.6493  lr: 0.0001 \n",
      "ep/it: 0- 579 niter:   580  0m 44s (- 1848m 53s) completed:  0%) loss: 3.8592  loss_rec: 0.5791  loss_vel: 0.2202  loss_commit: 158.5014  perplexity: 634.0058  lr: 0.0001 \n",
      "ep/it: 0- 589 niter:   590  0m 45s (- 1841m 52s) completed:  0%) loss: 3.2028  loss_rec: 0.5805  loss_vel: 0.2362  loss_commit: 125.2079  perplexity: 500.8316  lr: 0.0001 \n",
      "ep/it: 0- 599 niter:   600  0m 45s (- 1835m 17s) completed:  0%) loss: 3.0576  loss_rec: 0.5625  loss_vel: 0.2278  loss_commit: 119.0599  perplexity: 476.2395  lr: 0.0001 \n",
      "ep/it: 0- 609 niter:   610  0m 46s (- 1828m 50s) completed:  0%) loss: 4.8007  loss_rec: 0.5738  loss_vel: 0.2253  loss_commit: 205.7136  perplexity: 822.8545  lr: 0.0001 \n",
      "ep/it: 0- 619 niter:   620  0m 46s (- 1822m 31s) completed:  0%) loss: 5.9564  loss_rec: 0.5697  loss_vel: 0.2298  loss_commit: 263.5878  perplexity: 1054.3511  lr: 0.0001 \n",
      "ep/it: 0- 629 niter:   630  0m 47s (- 1816m 11s) completed:  0%) loss: 2.3035  loss_rec: 0.5620  loss_vel: 0.2123  loss_commit: 81.7708  perplexity: 327.0833  lr: 0.0001 \n",
      "ep/it: 0- 639 niter:   640  0m 48s (- 1810m 1s) completed:  0%) loss: 1.6419  loss_rec: 0.5759  loss_vel: 0.2080  loss_commit: 48.0987  perplexity: 192.3946  lr: 0.0001 \n",
      "ep/it: 0- 649 niter:   650  0m 48s (- 1804m 31s) completed:  0%) loss: 2.4009  loss_rec: 0.5444  loss_vel: 0.2213  loss_commit: 87.2909  perplexity: 349.1634  lr: 0.0001 \n",
      "ep/it: 0- 659 niter:   660  0m 49s (- 1799m 12s) completed:  0%) loss: 2.8511  loss_rec: 0.5627  loss_vel: 0.2175  loss_commit: 108.9842  perplexity: 435.9368  lr: 0.0001 \n",
      "ep/it: 0- 669 niter:   670  0m 49s (- 1793m 51s) completed:  0%) loss: 2.6693  loss_rec: 0.5590  loss_vel: 0.2177  loss_commit: 100.0733  perplexity: 400.2932  lr: 0.0001 \n",
      "ep/it: 0- 679 niter:   680  0m 50s (- 1788m 14s) completed:  0%) loss: 4.4053  loss_rec: 0.5058  loss_vel: 0.2087  loss_commit: 189.7544  perplexity: 759.0178  lr: 0.0001 \n",
      "ep/it: 0- 689 niter:   690  0m 51s (- 1782m 40s) completed:  0%) loss: 4.5927  loss_rec: 0.5447  loss_vel: 0.2038  loss_commit: 197.3050  perplexity: 789.2199  lr: 0.0001 \n",
      "ep/it: 0- 699 niter:   700  0m 51s (- 1777m 14s) completed:  0%) loss: 4.4241  loss_rec: 0.5239  loss_vel: 0.2055  loss_commit: 189.8705  perplexity: 759.4821  lr: 0.0001 \n",
      "ep/it: 0- 709 niter:   710  0m 52s (- 1771m 58s) completed:  0%) loss: 2.0239  loss_rec: 0.5052  loss_vel: 0.2171  loss_commit: 70.5088  perplexity: 282.0353  lr: 0.0001 \n",
      "ep/it: 0- 719 niter:   720  0m 52s (- 1767m 1s) completed:  0%) loss: 1.1111  loss_rec: 0.5327  loss_vel: 0.2315  loss_commit: 23.1305  perplexity: 92.5219  lr: 0.0001 \n",
      "ep/it: 0- 729 niter:   730  0m 53s (- 1762m 26s) completed:  0%) loss: 1.4166  loss_rec: 0.5234  loss_vel: 0.2127  loss_commit: 39.3395  perplexity: 157.3582  lr: 0.0001 \n",
      "ep/it: 0- 739 niter:   740  0m 54s (- 1758m 33s) completed:  0%) loss: 3.9130  loss_rec: 0.4894  loss_vel: 0.2149  loss_commit: 165.8102  perplexity: 663.2406  lr: 0.0001 \n",
      "ep/it: 0- 749 niter:   750  0m 54s (- 1754m 12s) completed:  0%) loss: 3.8135  loss_rec: 0.4956  loss_vel: 0.1995  loss_commit: 160.9060  perplexity: 643.6241  lr: 0.0001 \n",
      "ep/it: 0- 759 niter:   760  0m 55s (- 1750m 1s) completed:  0%) loss: 1.4216  loss_rec: 0.4958  loss_vel: 0.2210  loss_commit: 40.7669  perplexity: 163.0676  lr: 0.0001 \n",
      "ep/it: 0- 769 niter:   770  0m 55s (- 1745m 47s) completed:  0%) loss: 1.9419  loss_rec: 0.5073  loss_vel: 0.2174  loss_commit: 66.2923  perplexity: 265.1694  lr: 0.0001 \n",
      "ep/it: 0- 779 niter:   780  0m 56s (- 1741m 40s) completed:  0%) loss: 1.7992  loss_rec: 0.4688  loss_vel: 0.1931  loss_commit: 61.6963  perplexity: 246.7854  lr: 0.0001 \n",
      "ep/it: 0- 789 niter:   790  0m 57s (- 1737m 32s) completed:  0%) loss: 2.1207  loss_rec: 0.4702  loss_vel: 0.1935  loss_commit: 77.6904  perplexity: 310.7615  lr: 0.0001 \n",
      "ep/it: 0- 799 niter:   800  0m 57s (- 1733m 29s) completed:  0%) loss: 3.4642  loss_rec: 0.4795  loss_vel: 0.1942  loss_commit: 144.3812  perplexity: 577.5246  lr: 0.0001 \n",
      "ep/it: 0- 809 niter:   810  0m 58s (- 1729m 31s) completed:  0%) loss: 2.5017  loss_rec: 0.4768  loss_vel: 0.2032  loss_commit: 96.1635  perplexity: 384.6540  lr: 0.0001 \n",
      "ep/it: 0- 819 niter:   820  0m 58s (- 1725m 43s) completed:  0%) loss: 1.8779  loss_rec: 0.5076  loss_vel: 0.2195  loss_commit: 63.0233  perplexity: 252.0933  lr: 0.0001 \n",
      "ep/it: 0- 829 niter:   830  0m 59s (- 1721m 58s) completed:  0%) loss: 1.2410  loss_rec: 0.4657  loss_vel: 0.2067  loss_commit: 33.6000  perplexity: 134.3999  lr: 0.0001 \n",
      "ep/it: 0- 839 niter:   840  1m 0s (- 1718m 19s) completed:  0%) loss: 1.2952  loss_rec: 0.4430  loss_vel: 0.1890  loss_commit: 37.8871  perplexity: 151.5483  lr: 0.0001 \n",
      "ep/it: 0- 849 niter:   850  1m 0s (- 1714m 45s) completed:  0%) loss: 4.6419  loss_rec: 0.4790  loss_vel: 0.2005  loss_commit: 203.1327  perplexity: 812.5308  lr: 0.0001 \n",
      "ep/it: 0- 859 niter:   860  1m 1s (- 1711m 17s) completed:  0%) loss: 4.8449  loss_rec: 0.4450  loss_vel: 0.2038  loss_commit: 214.8993  perplexity: 859.5972  lr: 0.0001 \n",
      "ep/it: 0- 869 niter:   870  1m 1s (- 1708m 24s) completed:  0%) loss: 3.5467  loss_rec: 0.4671  loss_vel: 0.2116  loss_commit: 148.6898  perplexity: 594.7594  lr: 0.0001 \n",
      "ep/it: 0- 879 niter:   880  1m 2s (- 1705m 10s) completed:  0%) loss: 1.3686  loss_rec: 0.4406  loss_vel: 0.2002  loss_commit: 41.3966  perplexity: 165.5862  lr: 0.0001 \n",
      "ep/it: 0- 889 niter:   890  1m 3s (- 1702m 6s) completed:  0%) loss: 1.8227  loss_rec: 0.4628  loss_vel: 0.2100  loss_commit: 62.7483  perplexity: 250.9934  lr: 0.0001 \n",
      "ep/it: 0- 899 niter:   900  1m 3s (- 1699m 2s) completed:  0%) loss: 2.2661  loss_rec: 0.4715  loss_vel: 0.2062  loss_commit: 84.5727  perplexity: 338.2907  lr: 0.0001 \n",
      "ep/it: 0- 909 niter:   910  1m 4s (- 1695m 56s) completed:  0%) loss: 2.1093  loss_rec: 0.4653  loss_vel: 0.2081  loss_commit: 76.9962  perplexity: 307.9849  lr: 0.0001 \n",
      "ep/it: 0- 919 niter:   920  1m 4s (- 1693m 11s) completed:  0%) loss: 1.7877  loss_rec: 0.4436  loss_vel: 0.1884  loss_commit: 62.4967  perplexity: 249.9870  lr: 0.0001 \n",
      "ep/it: 0- 929 niter:   930  1m 5s (- 1690m 36s) completed:  0%) loss: 2.1446  loss_rec: 0.4516  loss_vel: 0.2058  loss_commit: 79.5082  perplexity: 318.0326  lr: 0.0001 \n",
      "ep/it: 0- 939 niter:   940  1m 5s (- 1687m 53s) completed:  0%) loss: 2.7333  loss_rec: 0.4304  loss_vel: 0.1886  loss_commit: 110.4293  perplexity: 441.7170  lr: 0.0001 \n",
      "ep/it: 0- 949 niter:   950  1m 6s (- 1685m 12s) completed:  0%) loss: 4.6571  loss_rec: 0.4610  loss_vel: 0.1971  loss_commit: 204.8786  perplexity: 819.5144  lr: 0.0001 \n",
      "ep/it: 0- 959 niter:   960  1m 7s (- 1682m 50s) completed:  0%) loss: 6.1607  loss_rec: 0.4647  loss_vel: 0.2005  loss_commit: 279.7879  perplexity: 1119.1514  lr: 0.0001 \n",
      "ep/it: 0- 969 niter:   970  1m 7s (- 1680m 17s) completed:  0%) loss: 3.4230  loss_rec: 0.4746  loss_vel: 0.2192  loss_commit: 141.9414  perplexity: 567.7655  lr: 0.0001 \n",
      "ep/it: 0- 979 niter:   980  1m 8s (- 1677m 33s) completed:  0%) loss: 2.4181  loss_rec: 0.4325  loss_vel: 0.1968  loss_commit: 94.3622  perplexity: 377.4487  lr: 0.0001 \n",
      "ep/it: 0- 989 niter:   990  1m 8s (- 1674m 47s) completed:  0%) loss: 2.2868  loss_rec: 0.4435  loss_vel: 0.1997  loss_commit: 87.1731  perplexity: 348.6923  lr: 0.0001 \n",
      "ep/it: 0- 999 niter:  1000  1m 9s (- 1672m 4s) completed:  0%) loss: 2.1005  loss_rec: 0.4525  loss_vel: 0.1929  loss_commit: 77.5759  perplexity: 310.3037  lr: 0.0001 \n",
      "ep/it: 0-1009 niter:  1010  1m 10s (- 1687m 16s) completed:  0%) loss: 2.5616  loss_rec: 0.4369  loss_vel: 0.1928  loss_commit: 101.4162  perplexity: 405.6647  lr: 0.0001 \n",
      "ep/it: 0-1019 niter:  1020  1m 11s (- 1685m 10s) completed:  0%) loss: 3.0393  loss_rec: 0.4507  loss_vel: 0.1963  loss_commit: 124.5264  perplexity: 498.1058  lr: 0.0001 \n",
      "ep/it: 0-1029 niter:  1030  1m 12s (- 1682m 40s) completed:  0%) loss: 6.8437  loss_rec: 0.4448  loss_vel: 0.2048  loss_commit: 314.8277  perplexity: 1259.3110  lr: 0.0001 \n",
      "ep/it: 0-1039 niter:  1040  1m 12s (- 1680m 0s) completed:  0%) loss: 4.0266  loss_rec: 0.4618  loss_vel: 0.2014  loss_commit: 173.2044  perplexity: 692.8177  lr: 0.0001 \n",
      "ep/it: 0-1049 niter:  1050  1m 13s (- 1677m 27s) completed:  0%) loss: 3.2843  loss_rec: 0.4182  loss_vel: 0.1848  loss_commit: 138.6830  perplexity: 554.7322  lr: 0.0001 \n",
      "ep/it: 0-1059 niter:  1060  1m 13s (- 1675m 5s) completed:  0%) loss: 3.0927  loss_rec: 0.4398  loss_vel: 0.1876  loss_commit: 127.9528  perplexity: 511.8112  lr: 0.0001 \n",
      "ep/it: 0-1069 niter:  1070  1m 14s (- 1672m 54s) completed:  0%) loss: 2.2694  loss_rec: 0.4311  loss_vel: 0.1953  loss_commit: 87.0332  perplexity: 348.1329  lr: 0.0001 \n",
      "ep/it: 0-1079 niter:  1080  1m 15s (- 1671m 2s) completed:  0%) loss: 2.3261  loss_rec: 0.4091  loss_vel: 0.1860  loss_commit: 91.2014  perplexity: 364.8057  lr: 0.0001 \n",
      "ep/it: 0-1089 niter:  1090  1m 15s (- 1668m 58s) completed:  0%) loss: 3.2020  loss_rec: 0.4397  loss_vel: 0.1928  loss_commit: 133.2932  perplexity: 533.1727  lr: 0.0001 \n",
      "ep/it: 0-1099 niter:  1100  1m 16s (- 1667m 1s) completed:  0%) loss: 4.8954  loss_rec: 0.4285  loss_vel: 0.1957  loss_commit: 218.4533  perplexity: 873.8132  lr: 0.0001 \n",
      "ep/it: 0-1109 niter:  1110  1m 16s (- 1664m 50s) completed:  0%) loss: 6.5334  loss_rec: 0.4280  loss_vel: 0.1966  loss_commit: 300.3534  perplexity: 1201.4135  lr: 0.0001 \n",
      "ep/it: 0-1119 niter:  1120  1m 17s (- 1662m 46s) completed:  0%) loss: 4.0287  loss_rec: 0.4120  loss_vel: 0.1927  loss_commit: 176.0207  perplexity: 704.0830  lr: 0.0001 \n",
      "ep/it: 0-1129 niter:  1130  1m 18s (- 1661m 3s) completed:  0%) loss: 1.7474  loss_rec: 0.4309  loss_vel: 0.1944  loss_commit: 60.9676  perplexity: 243.8706  lr: 0.0001 \n",
      "ep/it: 0-1139 niter:  1140  1m 18s (- 1658m 58s) completed:  0%) loss: 2.3426  loss_rec: 0.4352  loss_vel: 0.2123  loss_commit: 90.0630  perplexity: 360.2520  lr: 0.0001 \n",
      "ep/it: 0-1149 niter:  1150  1m 19s (- 1656m 57s) completed:  0%) loss: 4.1127  loss_rec: 0.4335  loss_vel: 0.2001  loss_commit: 178.9556  perplexity: 715.8225  lr: 0.0001 \n",
      "ep/it: 0-1159 niter:  1160  1m 19s (- 1654m 56s) completed:  0%) loss: 6.5080  loss_rec: 0.4524  loss_vel: 0.2012  loss_commit: 297.7507  perplexity: 1191.0029  lr: 0.0001 \n",
      "ep/it: 0-1169 niter:  1170  1m 20s (- 1652m 56s) completed:  0%) loss: 3.6873  loss_rec: 0.4319  loss_vel: 0.1962  loss_commit: 157.8638  perplexity: 631.4550  lr: 0.0001 \n",
      "ep/it: 0-1179 niter:  1180  1m 21s (- 1650m 55s) completed:  0%) loss: 2.3832  loss_rec: 0.4200  loss_vel: 0.1878  loss_commit: 93.4639  perplexity: 373.8555  lr: 0.0001 \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipcik/PycharmPhd/motion-vqvae/train_vq.py\", line 116, in <module>\n",
      "    trainer.train(train_loader, val_loader, eval_val_loader, eval_wrapper, plot_t2m)\n",
      "  File \"/home/dipcik/PycharmPhd/motion-vqvae/models/vq/vq_trainer.py\", line 132, in train\n",
      "    logs['loss'] += loss.mean().item()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train_vq.py --name lfq_namexx --gpu_id 0 --dataset_name t2m --batch_size 64 --num_quantizers 6 --max_epoch 50 --quantize_dropout_prob 0.2 --gamma 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard              2.16.2\n",
      "tensorboard-data-server  0.7.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list |grep tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_vq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
